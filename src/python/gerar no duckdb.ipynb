{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5007c85-3948-4c04-b54b-6ad18bc41a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def criar_diretorio(caminho: str) -> None:\n",
    "    \"\"\"Garante que o diretório existe.\"\"\"\n",
    "    os.makedirs(caminho, exist_ok=True)\n",
    "\n",
    "def salvar_dataframe_em_parquet_particionado_duckdb(\n",
    "    df: pd.DataFrame,\n",
    "    caminho_destino: str,\n",
    "    colunas_particao: List[str]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva um DataFrame como Parquet particionado usando DuckDB,\n",
    "    criando as pastas no formato hive (coluna=valor/).\n",
    "    \"\"\"\n",
    "    criar_diretorio(caminho_destino)\n",
    "\n",
    "    con = duckdb.connect(database=':memory:')  # Pode ser in-memory porque só queremos salvar\n",
    "\n",
    "    con.register('temp_table', df)\n",
    "\n",
    "    # Cria diretório de destino absoluto\n",
    "    caminho_destino = os.path.abspath(caminho_destino)\n",
    "\n",
    "    # COPY TO ... (partition_by colunas)\n",
    "    con.execute(f\"\"\"\n",
    "        COPY temp_table \n",
    "        TO '{caminho_destino}' \n",
    "        (FORMAT PARQUET, PARTITION_BY ({', '.join(colunas_particao)}))\n",
    "    \"\"\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "\n",
    "\n",
    "df_pessoas = gerar_base_historica_ficticia()\n",
    "\n",
    "salvar_dataframe_em_parquet_particionado_duckdb(\n",
    "    df=df_pessoas,\n",
    "    caminho_destino=\"../../dados/ficticios/uf-municipio\",\n",
    "    colunas_particao=['uf', 'municipio']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50c53d-d46f-4de3-adbc-6cfbffd6df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import numpy as np\n",
    "\n",
    "def gerar_base_historica_ficticia():\n",
    "\n",
    "    # Inicializa o gerador de dados falsos\n",
    "    faker = Faker('pt_BR')\n",
    "    \n",
    "    # Define o número de linhas que você quer gerar\n",
    "    n_pessoas = 1000\n",
    "    \n",
    "    # Gera os dados de pessoas com municípios\n",
    "    dados_pessoas = {\n",
    "        'uf': np.random.choice(['SP', 'RJ', 'MG', 'RS', 'BA'], size=n_pessoas),\n",
    "        'municipio': [faker.city() for _ in range(n_pessoas)],\n",
    "        'nome': [faker.name() for _ in range(n_pessoas)],\n",
    "        'data_inicio': [faker.date_between(start_date='-5y', end_date='today') for _ in range(n_pessoas)],\n",
    "        'data_fim': [faker.date_between(start_date='today', end_date='+5y') for _ in range(n_pessoas)],\n",
    "    }\n",
    "    \n",
    "    # Cria o DataFrame de pessoas\n",
    "    df_pessoas = pd.DataFrame(dados_pessoas)\n",
    "    \n",
    "    # Converte para datetime\n",
    "    df_pessoas['data_inicio'] = pd.to_datetime(df_pessoas['data_inicio'])\n",
    "    df_pessoas['data_fim'] = pd.to_datetime(df_pessoas['data_fim'])\n",
    "    \n",
    "    # Garante que data_inicio <= data_fim\n",
    "    df_pessoas.loc[df_pessoas['data_inicio'] > df_pessoas['data_fim'], ['data_inicio', 'data_fim']] = \\\n",
    "        df_pessoas.loc[df_pessoas['data_inicio'] > df_pessoas['data_fim'], ['data_fim', 'data_inicio']].values\n",
    "\n",
    "    return df_pessoas\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
